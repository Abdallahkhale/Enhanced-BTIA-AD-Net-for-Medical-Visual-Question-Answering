2026-01-28 22:28:56,044 - training - INFO - Starting training with config: {'model': {'vision_encoder': 'microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224', 'text_encoder': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext', 'hidden_dim': 768, 'num_heads': 8, 'num_attention_layers': 2, 'dropout': 0.3, 'top_k_answers': 5, 'fusion_method': 'btia', 'use_answer_distillation': True}, 'training': {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'epochs': 50, 'warmup_ratio': 0.1, 'fp16': True, 'gradient_accumulation_steps': 2, 'gradient_checkpointing': True, 'save_every_epoch': True, 'checkpoint_dir': 'checkpoints', 'resume_from': None, 'early_stopping_patience': 10, 'early_stopping_metric': 'val_accuracy'}, 'data': {'image_size': 224, 'max_question_length': 64, 'max_answer_length': 32, 'use_slake_augmentation': True, 'train_split': 0.8, 'num_workers': 4, 'vqa_rad_dir': 'data/vqa_rad', 'slake_dir': 'data/slake'}, 'logging': {'log_dir': 'logs', 'log_every_n_steps': 10, 'use_tensorboard': True}}
2026-01-28 22:28:56,058 - training - INFO - Creating data loaders...
2026-01-28 22:29:06,492 - training - INFO - Number of answers: 221
2026-01-28 22:29:06,494 - training - INFO - Creating model...
2026-01-28 22:29:14,229 - training - INFO - Building answer embedding cache...
2026-01-28 22:29:18,283 - training - INFO - Model parameters: {'total': 251754683, 'trainable': 251754683, 'frozen': 0}
2026-01-28 22:29:18,286 - training - INFO - Starting training...
2026-01-28 22:29:18,287 - training - INFO - 
==================================================
2026-01-28 22:29:18,288 - training - INFO - Epoch 1/50
2026-01-28 22:29:18,290 - training - INFO - ==================================================
2026-01-28 22:32:03,014 - training - INFO - Train - Loss: 7.1406, Acc: 0.0095
2026-01-28 22:32:54,589 - training - INFO - Val - Loss: 6.1568, Overall: 0.0576, Closed: 0.1036, Open: 0.0000
2026-01-28 22:33:04,628 - training - INFO - New best model saved! Accuracy: 0.0576
2026-01-28 22:33:04,630 - training - INFO - 
==================================================
2026-01-28 22:33:04,631 - training - INFO - Epoch 2/50
2026-01-28 22:33:04,631 - training - INFO - ==================================================
2026-01-28 22:39:32,361 - training - INFO - Train - Loss: 6.7796, Acc: 0.0335
2026-01-28 22:40:47,107 - training - INFO - Val - Loss: 5.5921, Overall: 0.2616, Closed: 0.4701, Open: 0.0000
2026-01-28 22:41:04,738 - training - INFO - New best model saved! Accuracy: 0.2616
2026-01-28 22:41:04,746 - training - INFO - 
==================================================
2026-01-28 22:41:04,747 - training - INFO - Epoch 3/50
2026-01-28 22:41:04,749 - training - INFO - ==================================================
2026-01-28 22:45:15,208 - training - INFO - Train - Loss: 6.4232, Acc: 0.0993
2026-01-28 22:50:08,024 - training - INFO - Val - Loss: 5.2219, Overall: 0.2506, Closed: 0.4502, Open: 0.0000
2026-01-28 22:50:15,883 - training - INFO - 
==================================================
2026-01-28 22:50:15,886 - training - INFO - Epoch 4/50
2026-01-28 22:50:15,888 - training - INFO - ==================================================
2026-01-28 22:52:31,876 - training - INFO - Train - Loss: 6.1995, Acc: 0.1657
2026-01-28 22:54:12,526 - training - INFO - Val - Loss: 4.9564, Overall: 0.2639, Closed: 0.4741, Open: 0.0000
2026-01-28 22:54:27,686 - training - INFO - New best model saved! Accuracy: 0.2639
2026-01-28 22:54:27,687 - training - INFO - 
==================================================
2026-01-28 22:54:27,688 - training - INFO - Epoch 5/50
2026-01-28 22:54:27,689 - training - INFO - ==================================================
2026-01-28 22:59:51,840 - training - INFO - Train - Loss: 5.9365, Acc: 0.2232
2026-01-28 23:03:39,885 - training - INFO - Val - Loss: 4.7589, Overall: 0.2639, Closed: 0.4741, Open: 0.0000
2026-01-28 23:04:08,880 - training - INFO - 
==================================================
2026-01-28 23:04:08,882 - training - INFO - Epoch 6/50
2026-01-28 23:04:08,884 - training - INFO - ==================================================
